{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Logistic Regression From Scratch</h1>\n",
    "<h3>Start with Loading in Data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20.13, 28.25, 131.2, 1261.0, 0.0, 0.1034, 0.144, 0.09791, 0.1752, 0.05533, 0.7655, 2.463, 5.203, 99.04, 0.005769, 0.02423, 0.0395, 0.01678, 0.01898, 0.002498, 23.69, 38.25, 155.0, 1731.0, 0.1166, 0.1922, 0.3215, 0.1628, 0.2572, 0.06637]\n",
      "[132.0, 6.2, 6.47, 36.21, 1.0, 62.0, 30.77, 14.14, 45.0]\n"
     ]
    }
   ],
   "source": [
    "def load_data(file_path):\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            # Split the line into tokens based on whitespace separation\n",
    "            tokens = line.strip().split()\n",
    "\n",
    "            # Convert \"Present\" or \"Absent\" to binary. Assuming this is always the 5th column in the data.\n",
    "            binary_feature = 1 if tokens[4] == \"Present\" else 0\n",
    "            \n",
    "            # Replace the \"Present\"/\"Absent\" with its binary representation\n",
    "            tokens[4] = binary_feature\n",
    "\n",
    "            # All tokens except the last are features (convert all to floats)\n",
    "            features = [float(token) for token in tokens[:-1]]\n",
    "\n",
    "            # The last token is the label (convert to int)\n",
    "            label = int(tokens[-1])\n",
    "\n",
    "            # Add the feature vector and label to the data lists\n",
    "            data.append(features)\n",
    "            labels.append(label)\n",
    "\n",
    "    return data, labels\n",
    "\n",
    "\n",
    "dataset1 = './project3_dataset1.txt'\n",
    "dataset2 = './project3_dataset2.txt'\n",
    "\n",
    "data1, labels1 = load_data(dataset1)\n",
    "data2, labels2 = load_data(dataset2)\n",
    "\n",
    "print(data1[0])\n",
    "print(data2[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Add Intercept Term and Initialize Weights</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Intercepts\n",
    "data1_with_intercept = [[1] + row for row in data1]\n",
    "data2_with_intercept = [[1] + row for row in data2]\n",
    "\n",
    "# Convert your data to numpy arrays\n",
    "data1_with_intercept = np.array(data1_with_intercept)\n",
    "labels1 = np.array(labels1)\n",
    "data2_with_intercept = np.array(data2_with_intercept)\n",
    "labels2 = np.array(labels2)\n",
    "\n",
    "# Initialize Weights\n",
    "weights1 = [random.uniform(-0.01, 0.01) for _ in range(len(data1_with_intercept[0]))]\n",
    "weights2 = [random.uniform(-0.01, 0.01) for _ in range(len(data2_with_intercept[0]))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Model Training</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    if z < 0:\n",
    "        return math.exp(z) / (1 + math.exp(z))\n",
    "    else:\n",
    "        return 1 / (1 + math.exp(-z))\n",
    "\n",
    "def compute_gradient(X, y, theta):\n",
    "    m = len(y)\n",
    "    gradient = [0 for _ in range(len(theta))]\n",
    "    \n",
    "    for i in range(m):\n",
    "        xi = X[i]\n",
    "        yi = y[i]\n",
    "        prediction = sigmoid(sum(w * x for w, x in zip(theta, xi)))\n",
    "        for j in range(len(theta)):\n",
    "            gradient[j] += (prediction - yi) * xi[j]\n",
    "    \n",
    "    gradient = [g / m for g in gradient]\n",
    "    return gradient\n",
    "\n",
    "def gradient_descent(X, y, theta, alpha, iterations, lambda_reg):\n",
    "    for _ in range(iterations):\n",
    "        gradient = compute_gradient(X, y, theta)\n",
    "        # Apply L2 regularization\n",
    "        regularization = [lambda_reg * t for t in theta]\n",
    "        regularization[0] = 0  # Do not regularize the bias term\n",
    "        theta = [t - alpha * (g + r) for t, g, r in zip(theta, gradient, regularization)]\n",
    "    return theta\n",
    "\n",
    "# Predict Function\n",
    "def predict(X, theta):\n",
    "    return [1 if sigmoid(sum(w * x for w, x in zip(theta, xi))) >= 0.5 else 0 for xi in X]\n",
    "\n",
    "\n",
    "# Hyperparameters\n",
    "alpha = 0.01\n",
    "iterations = 1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Results Dataset 1\n",
      "Current Alpha: 0.01\n",
      "Current Lambda: 0\n",
      "Current Lambda: 0.1\n",
      "Current Lambda: 1\n",
      "Current Alpha: 0.1\n",
      "Current Lambda: 0\n",
      "Current Lambda: 0.1\n",
      "Current Lambda: 1\n",
      "Current Alpha: 1\n",
      "Current Lambda: 0\n",
      "Current Lambda: 0.1\n",
      "Current Lambda: 1\n",
      "Starting Results Dataset 2\n",
      "Current Alpha: 0.01\n",
      "Current Lambda: 0\n",
      "Current Lambda: 0.1\n",
      "Current Lambda: 1\n",
      "Current Alpha: 0.1\n",
      "Current Lambda: 0\n",
      "Current Lambda: 0.1\n",
      "Current Lambda: 1\n",
      "Current Alpha: 1\n",
      "Current Lambda: 0\n",
      "Current Lambda: 0.1\n",
      "Current Lambda: 1\n",
      "{'Alpha': 0.01, 'Lambda': 0, 'Accuracy': 0.9139097744360903, 'Precision': 0.8874317719790865, 'Recall': 0.8664889883588837, 'F1': 0.8739105376919184, 'AUC': 0.9038377780045999}\n",
      "{'Alpha': 0.01, 'Lambda': 0.1, 'Accuracy': 0.8821428571428571, 'Precision': 0.8628014074682155, 'Recall': 0.8255052040791666, 'F1': 0.8251243065586384, 'AUC': 0.8719732136593057}\n",
      "{'Alpha': 0.01, 'Lambda': 1, 'Accuracy': 0.4608082706766917, 'Precision': 0.6035087719298244, 'Recall': 0.6618000279290601, 'F1': 0.40450882829051843, 'AUC': 0.5309000139645301}\n",
      "{'Alpha': 0.1, 'Lambda': 0, 'Accuracy': 0.8910087719298246, 'Precision': 0.833662826706305, 'Recall': 0.8682149435630997, 'F1': 0.8468574970896071, 'AUC': 0.8868097658774827}\n",
      "{'Alpha': 0.1, 'Lambda': 0.1, 'Accuracy': 0.49016290726817047, 'Precision': 0.57437343358396, 'Recall': 0.7398701298701298, 'F1': 0.4586614711614711, 'AUC': 0.5199350649350649}\n",
      "{'Alpha': 0.1, 'Lambda': 1, 'Accuracy': 0.49407894736842106, 'Precision': 0.5245614035087719, 'Recall': 0.6559521041618228, 'F1': 0.40266673742668846, 'AUC': 0.5279760520809114}\n",
      "{'Alpha': 1, 'Lambda': 0, 'Accuracy': 0.8980263157894737, 'Precision': 0.8579966628048471, 'Recall': 0.8615482768964329, 'F1': 0.855968777965594, 'AUC': 0.8894883373060543}\n",
      "{'Alpha': 1, 'Lambda': 0.1, 'Accuracy': 0.5414473684210527, 'Precision': 0.39824561403508774, 'Recall': 0.3346997322453143, 'F1': 0.20551549899375984, 'AUC': 0.5173498661226572}\n",
      "{'Alpha': 1, 'Lambda': 1, 'Accuracy': 0.6273809523809523, 'Precision': 0.0, 'Recall': 0.0, 'F1': 0.0, 'AUC': 0.5}\n",
      "{'Alpha': 0.01, 'Lambda': 0, 'Accuracy': 0.6101757631822388, 'Precision': 0.35101754398578283, 'Recall': 0.54375, 'F1': 0.3965697711203647, 'AUC': 0.5794676470044118}\n",
      "{'Alpha': 0.01, 'Lambda': 0.1, 'Accuracy': 0.603422756706753, 'Precision': 0.32071523278684405, 'Recall': 0.5459411421911422, 'F1': 0.36439898989898994, 'AUC': 0.6116824993870773}\n",
      "{'Alpha': 0.01, 'Lambda': 1, 'Accuracy': 0.5608233117483812, 'Precision': 0.2634439228386385, 'Recall': 0.4960576923076923, 'F1': 0.29689888666158, 'AUC': 0.5298312594268476}\n",
      "{'Alpha': 0.1, 'Lambda': 0, 'Accuracy': 0.6493987049028677, 'Precision': 0.3222965440356745, 'Recall': 0.36276845961056486, 'F1': 0.31299069799819423, 'AUC': 0.5905348031013729}\n",
      "{'Alpha': 0.1, 'Lambda': 0.1, 'Accuracy': 0.5275670675300648, 'Precision': 0.30144927536231886, 'Recall': 0.5463203463203463, 'F1': 0.3334894708233095, 'AUC': 0.5150283050283051}\n",
      "{'Alpha': 0.1, 'Lambda': 1, 'Accuracy': 0.5931082331174838, 'Precision': 0.21859389454209066, 'Recall': 0.30769230769230765, 'F1': 0.1833231474407945, 'AUC': 0.5038461538461538}\n",
      "{'Alpha': 1, 'Lambda': 0, 'Accuracy': 0.6, 'Precision': 0.2597527706734868, 'Recall': 0.42624060150375936, 'F1': 0.2947852147852148, 'AUC': 0.5575638980832854}\n",
      "{'Alpha': 1, 'Lambda': 0.1, 'Accuracy': 0.5462534690101757, 'Precision': 0.14625346901017575, 'Recall': 0.4, 'F1': 0.21237076648841358, 'AUC': 0.5}\n",
      "{'Alpha': 1, 'Lambda': 1, 'Accuracy': 0.34625346901017573, 'Precision': 0.34625346901017573, 'Recall': 1.0, 'F1': 0.5105398238828507, 'AUC': 0.5}\n"
     ]
    }
   ],
   "source": [
    "def train_and_evaluate(X, y, folds, alphas, iterations, lambda_regs):\n",
    "    results = []\n",
    "\n",
    "    kf = KFold(n_splits=folds)\n",
    "    for alpha in alphas:\n",
    "        print(f\"Current Alpha: {alpha}\")\n",
    "        for lambda_reg in lambda_regs:\n",
    "            print(f\"Current Lambda: {lambda_reg}\")\n",
    "            metrics = {\n",
    "                \"Alpha\": alpha, \n",
    "                \"Lambda\": lambda_reg, \n",
    "                \"Accuracy\": [], \n",
    "                \"Precision\": [], \n",
    "                \"Recall\": [], \n",
    "                \"F1\": [], \n",
    "                \"AUC\": []\n",
    "            }\n",
    "\n",
    "            for train_index, test_index in kf.split(X):\n",
    "                X_train, X_test = X[train_index], X[test_index]\n",
    "                y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "                theta = [0 for _ in range(X_train.shape[1])]\n",
    "                theta = gradient_descent(X_train, y_train, theta, alpha, iterations, lambda_reg)\n",
    "\n",
    "                predictions = predict(X_test, theta)\n",
    "\n",
    "                # Calculate and store metrics\n",
    "                metrics[\"Accuracy\"].append(accuracy_score(y_test, predictions))\n",
    "                metrics[\"Precision\"].append(precision_score(y_test, predictions, zero_division=0))\n",
    "                metrics[\"Recall\"].append(recall_score(y_test, predictions))\n",
    "                metrics[\"F1\"].append(f1_score(y_test, predictions))\n",
    "                metrics[\"AUC\"].append(roc_auc_score(y_test, predictions))\n",
    "\n",
    "            # Compute average of each metric and store it\n",
    "            averaged_metrics = {metric: np.mean(values) for metric, values in metrics.items() if metric not in [\"Alpha\", \"Lambda\"]}\n",
    "            results.append({**{\"Alpha\": alpha, \"Lambda\": lambda_reg}, **averaged_metrics})\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# Hyperparameters to test\n",
    "alphas = [0.01, 0.1, 1]  # Learning rates\n",
    "lambda_regs = [0, 0.1, 1]  # Regularization strengths\n",
    "\n",
    "# Conduct analysis\n",
    "print(\"Starting Results Dataset 1\")\n",
    "results_dataset1 = train_and_evaluate(data1_with_intercept, labels1, 10, alphas, iterations, lambda_regs)\n",
    "print(\"Starting Results Dataset 2\")\n",
    "results_dataset2 = train_and_evaluate(data2_with_intercept, labels2, 10, alphas, iterations, lambda_regs)\n",
    "\n",
    "# Print or analyze the results\n",
    "for result in results_dataset1:\n",
    "    print(result)\n",
    "\n",
    "for result in results_dataset2:\n",
    "    print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
